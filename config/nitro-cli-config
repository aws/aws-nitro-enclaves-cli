#!/bin/bash

# Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.
# SPDX-License-Identifier: Apache-2.0

################################################################
# Nitro CLI environment configuration script.
#
# This script provides:
# - Nitro Enclaves driver build, insertion, removal and clean-up
# - Huge page number configuration, as needed for enclave memory
# Depending on the operation, it might require root privileges.
################################################################

set -eu

# The directory holding the Nitro Enclaves driver source.
DRIVER_DIR="."

# The name of the Nitro Enclaves driver.
DRIVER_NAME="nitro_enclaves"

# The name of the Nitro Enclaves resource directories.
RES_DIR_NAME="nitro_enclaves"

# The maximum percentage of free memory available.
FREE_MEM_MAX_PERCENTAGE=50

# The name of the NE group that will own the device file.
NE_GROUP_NAME="ne"

# The name of the udev rules file for the device file.
UDEV_RULES_FILE="99-nitro-enclaves.rules"

# The current user.
THIS_USER="$(whoami)"

# Flag for deciding whether to print stdout messages or not.
VERBOSE="0"

# A flag indicating if we must reset the terminal. This is needed when
# inserting the driver and configuring the NE access group, since group
# visibility normally requires a log-out / log-in or reboot.
SHELL_RESET="0"

# A flag used for skipping the shell reset - only used when setting
# up the environment for installing the integration tests RPM.
SKIP_SHELL_RESET="0"

# Trap any exit condition, including all fatal errors.
trap 'error_handler $? $LINENO' EXIT
error_handler() {
    if [ "$1" -ne 0 ]; then
        # error handling goes here
        echo "Error on line $2 with status: $1"
    fi
}

# Print an error message and fail.
function fail {
    echo "Error: $1"
    exit 1
}

# Check if a provided string is a positive integer.
function check_if_number {
    [[ "$1" =~ ^[0-9]+$ ]]
}

# Run the provided command under 'sudo'.
function sudo_run {
    if [ "$(id -u)" -eq 0 ]
    then
        "$SHELL" -c "$@"
    else
        sudo -- "$SHELL" -c "$@"
    fi

    return $?
}

# Configure the needed number of huge pages.
function configure_huge_pages {
    local needed_mem
    local free_mem
    local huge_page_size

    if [ "$VERBOSE" = "1" ]; then
        echo "Configuring the huge page memory..."
    fi

    # Get the requested memory, trimming starting and ending whitespace.
    needed_mem="$1"

    # Fetch the total free memory and size of a huge page.
    free_mem=$(grep -i "memfree" /proc/meminfo | tr -s ' ' | cut -d' ' -f2)
    huge_page_size=$(grep -i "hugepagesize" /proc/meminfo | tr -s ' ' | cut -d' ' -f2)

    # Check if the required parameters have been obtained.
    check_if_number "$needed_mem" || fail "The needed memory amount ($needed_mem) is invalid."
    check_if_number "$free_mem" || fail "The free memory amount ($free_mem) is invalid."
    check_if_number "$huge_page_size" || fail "The huge page size ($huge_page_size) is invalid."

    # The available memory and huge page size are given in kB. Convert the needed memory to kB as well.
    [ "$needed_mem" -gt 0 ] || fail "Requested memory must be greater than 0."
    needed_mem=$((needed_mem * 1024))

    # Obtain and set the corresponding number of huge pages.
    num_pages=$((1 + (needed_mem - 1) / huge_page_size))
    actual_mem=$((num_pages * huge_page_size))

    # The maximum amount of free memory available for use as huge pages.
    free_mem=$((free_mem * FREE_MEM_MAX_PERCENTAGE / 100))

    # Fail if the requested memory is larger than what's available.
    [ "$actual_mem" -le "$free_mem" ] || fail "The actual memory amount ($actual_mem kB) is greater than the memory limit ($free_mem kB)."

    # Configure the number of huge pages.
    sudo_run "echo $num_pages > /proc/sys/vm/nr_hugepages" || fail "Failed to configure the number of huge pages."

    # Verify that the exact value was written (value may be smaller if the instance has too little available memory).
    actual_num_pages="$(cat /proc/sys/vm/nr_hugepages)"
    [ "$num_pages" -eq "$actual_num_pages" ] || fail "Insufficient huge pages available ($actual_num_pages instead of the $num_pages needed)."

    if [ "$VERBOSE" = "1" ]; then
        echo "Done."
    fi
}

# Print the script's usage instructions.
function print_usage {
    echo "Usage: $0 [-d <driver-directory>] [-b] [-c] [-i] [-r] [-h] [-m <memory_mb_needed>] [-p <cpu_pool>] [-t <cpu_count_cpu_pool>]"
    echo -e "\t-d: The path to the directory containing the driver source code, including headers."
    echo -e "\t-b: Build the driver."
    echo -e "\t-c: Clean up the driver build."
    echo -e "\t-i: Insert the driver and configure its ownership and permissions."
    echo -e "\t-r: Remove the driver."
    echo -e "\t-h: Print these help messages."
    echo -e "\t-m: The amount of memory that will be needed for running enclaves, in megabytes."
    echo -e "\t-p: The CPU pool that is taken from the parent instance and made available for enclaves. The pool format"
    echo -e "\t    is given in: https://www.kernel.org/doc/html/latest/admin-guide/kernel-parameters.html#cpu-lists"
    echo -e "\t-t: The CPU count of the NE CPU pool to be auto-generated by this script and then configured."
}

# Verify that the provided driver directory is correct.
function verify_driver_directory {
    declare -a subdirs=("include/linux" "include/uapi/linux" "drivers/virt/$DRIVER_NAME")
    for subdir in "${subdirs[@]}"; do
        [ -d "$DRIVER_DIR/$subdir" ] || return 1
    done

    return 0
}

# Clean the driver.
function driver_clean {
    if [ "$VERBOSE" = "1" ]; then
        echo "Cleaning the driver... "
    fi
    make clean &> /dev/null || fail "Failed to clean driver."
    if [ "$VERBOSE" = "1" ]; then
        echo "Done."
    fi
}

# Remove the driver.
function driver_remove {
    if [ "$VERBOSE" = "1" ]; then
        echo "Removing the driver..."
    fi

    # Attempt to remove the driver.
    sudo_run "rmmod $DRIVER_NAME &> /dev/null" || fail "Failed to remove driver."

    # Verify that the driver has indeed been removed.
    [ "$(lsmod | grep -cw $DRIVER_NAME)" -eq 0 ] || fail "The driver is still visible."

    if [ "$VERBOSE" = "1" ]; then
        echo "Done."
    fi
}

# Build the driver.
function driver_build {
    if [ "$VERBOSE" = "1" ]; then
        echo "Building the driver..."
    fi
    make &> /dev/null || fail "Failed to build driver."
    if [ "$VERBOSE" = "1" ]; then
        echo "Done."
    fi
}

# Configure a given directory for root:$NE_GROUP_NAME ownership and 775 permissions.
function configure_resource_directory {
    sudo_run "mkdir -p $1" || fail "Could not create directory \"$1\"."
    sudo_run "chown root:$NE_GROUP_NAME $1" || fail "Could not set ownership for directory \"$1\"."

    # We set permissions to 775 since the owner and the group should get full permissions. Any other
    # users may read the contents of the directory and access its files, but they cannot remove any
    # files inside the directory, which prevents unauthorised removal of the log file and any enclave
    # socket (therefore, other users cannot terminate enclaves).
    sudo_run "chmod 775 $1" || fail "Could not set permissions for directory \"$1\"."
}

# Configure the resource directories for Nitro CLI logging and sockets.
function configure_resource_directories {
    # Configure the directory that will hold enclave process sockets.
    configure_resource_directory "/var/run/$RES_DIR_NAME"

    # Configure the directory that will hold logs.
    configure_resource_directory "/var/log/$RES_DIR_NAME"
}

# Insert the driver and configure udev after it is inserted.
function driver_insert {
    local log_file="/var/log/$RES_DIR_NAME/nitro_enclaves.log"
    local loop_idx=0

    # Remove an older driver if it is inserted.
    if [ "$(lsmod | grep -cw $DRIVER_NAME)" -gt 0 ]; then
        driver_remove
    fi

    if [ "$VERBOSE" = "1" ]; then
        echo "Inserting the driver..."
    fi

    # Insert the new driver.
    sudo_run "insmod $DRIVER_NAME.ko" || fail "Failed to insert driver."

    # Verify that the new driver has been inserted.
    [ "$(lsmod | grep -cw $DRIVER_NAME)" -eq 1 ] || fail "The driver is not visible."

    if [ "$VERBOSE" = "1" ]; then
        echo "Configuring the device file..."
    fi

    # Create the NE group if it doesn't already exist.
    if [ "$(grep -cw $NE_GROUP_NAME /etc/group)" -eq 0 ]; then
        sudo_run "groupadd $NE_GROUP_NAME"
    fi

    # Check that the group exists.
    sudo_run "getent group $NE_GROUP_NAME &> /dev/null" || fail "The group '$NE_GROUP_NAME' is not present."

    # Define the udev rules file. The string will be expanded twice (once below and the second time when it is
    # passed as an argument to $SHELL) and we need the double-quotes to make it into the rules file; hence, we
    # need to provide them pre-pre-expanded, i.e <\\\"> (since these expand to <\"> which expands to <">).
    sudo_run "echo KERNEL==\\\"$DRIVER_NAME\\\" SUBSYSTEM==\\\"misc\\\" OWNER=\\\"root\\\" GROUP=\\\"$NE_GROUP_NAME\\\" MODE=\\\"0660\\\" > /etc/udev/rules.d/$UDEV_RULES_FILE" || fail "Could not write udev rules file."

    # Trigger the udev rule.
    sudo_run "udevadm control --reload"
    sudo_run "udevadm trigger /dev/$DRIVER_NAME" || fail "Could not apply the NE udev rule."

    # The previous operation may need some time to complete.
    while [ "$NE_GROUP_NAME" != "$(stat -c '%G' /dev/$DRIVER_NAME)" ] && [ "$loop_idx" -lt 3 ]; do
        sleep 1
        loop_idx=$((loop_idx+1))
    done

    # Verify that the driver now has correct ownership and permissions
    [ "root" == "$(stat -c '%U' /dev/$DRIVER_NAME)" ] || fail "Device file has incorrect owner."
    [ "$NE_GROUP_NAME" == "$(stat -c '%G' /dev/$DRIVER_NAME)" ] || fail "Device file has incorrect group."
    [ "660" == "$(stat -c '%a' /dev/$DRIVER_NAME)" ] || fail "Device file has incorrect permissions."

    # We also need to add the non-root user to the NE group.
    if [ "$VERBOSE" = "1" ]; then
        echo "Adding user '$THIS_USER' to the group '$NE_GROUP_NAME'..."
    fi
    sudo_run "usermod -a -G $NE_GROUP_NAME $THIS_USER" || fail "Could not add user to the NE group."
    if [ "$VERBOSE" = "1" ]; then
        echo "Done."
    fi

    # We configure the relevant resource directories.
    if [ "$VERBOSE" = "1" ]; then
        echo "Configuring the resource directories..."
    fi
    configure_resource_directories
    if [ "$VERBOSE" = "1" ]; then
        echo "Done."
    fi

    # Lastly, we touch the log file so that any user may start a CLI instance at any time.
    # Otherwise, users outside of the group won't be able to start a CLI instance (since they won't have
    # permission to create the log file) until a valid user does so first.
    sudo_run "touch $log_file" || fail "Failed to initialize log file."
    sudo_run "chown root:$NE_GROUP_NAME $log_file && chmod 766 $log_file" || fail "Failed to set log file permissions."

    # If we have configured the group membership but the user still doesn't see it, we would normally need to
    # log-out and log-in or reboot. We avoid this by resetting the shell with the existing user. This must
    # always be done last in the script.
    if [ "$(groups | grep -cw $NE_GROUP_NAME)" -eq 0 ]; then
        SHELL_RESET="1"
    fi
}

# Run a function inside the driver directory.
function run_in_driver_dir {
    local driver_source_dir

    verify_driver_directory || fail "Driver directory '$DRIVER_DIR' is invalid."
    driver_source_dir="$DRIVER_DIR/drivers/virt/$DRIVER_NAME"
    pushd "$driver_source_dir" &> /dev/null || fail "Driver source directory '$driver_source_dir' can't be accessed."

    # Run the function here.
    "$@"

    popd &> /dev/null
}

# Configure the CPU pool.
function configure_cpu_pool {
    if [ "$VERBOSE" = "1" ]; then
        echo "Configuring the enclave CPU pool..."
    fi
    sudo_run "echo $1 > /sys/module/nitro_enclaves/parameters/ne_cpus" || fail "Failed to configure the CPU pool."
    if [ "$VERBOSE" = "1" ]; then
        echo "Done."
    fi
}

# Configure the CPU pool using the provided CPU count.
# Auto-generate a CPU pool given the following conditions:
# * All the CPUs need to be from the same NUMA node.
# * CPU 0 and its siblings need to remain available to the primary / parent VM.
# * Full CPU core(s) need(s) to be included in the CPU pool.
function configure_cpu_pool_by_cpu_count {
    local core_id=""
    local cpu_0_numa_node=""
    local cpu_pool=""
    local cpu_pool_array=()
    local cpu_pool_count="$1"
    local cpus_per_numa_node=""
    local nr_cpus=""
    local nr_cpus_per_numa_node=""
    local nr_numa_nodes=""
    local nr_threads_per_core=""
    local threads_per_core=""
    local threads_per_core_count=""

    if [ "$VERBOSE" = "1" ]; then
        echo "Auto-generating the enclave CPU pool by using the CPU count..."
    fi

    # Get the number of available CPUs, CPU threads (siblings) per core and the NUMA nodes count.
    nr_cpus="$(lscpu | grep "^CPU(s):" | cut -d ":" -f 2 | tr -d " \t")"

    [ -z "$nr_cpus" ] && fail "Failed to get the number of CPUs."

    nr_numa_nodes="$(lscpu | grep "^NUMA node(s):" | cut -d ":" -f 2 | tr -d " \t")"

    [ -z "$nr_numa_nodes" ] && fail "Failed to get the number of available NUMA nodes."

    nr_threads_per_core="$(lscpu | grep "^Thread(s) per core:" | cut -d ":" -f 2 | tr -d " \t")"

    [ -z "$nr_threads_per_core" ] && fail "Failed to get the number of threads per core."

    # CPU 0 and its siblings need to remain available to the primary / parent VM.
    # Get its NUMA node to count for remaining CPUs in this NUMA node.
    cpu_0_numa_node="$(lscpu -p=cpu,node | grep -v "#" | grep "^0," | cut -d "," -f 2)"

    [ -z "$cpu_0_numa_node" ] && fail "Failed to get the NUMA node of CPU 0."

    # Sanity check the given CPU count for the NE CPU pool.
    check_if_number "$cpu_pool_count" || fail "The CPU count value ($cpu_pool_count) is invalid."

    [ "$cpu_pool_count" -gt 0 ] || fail "Provided CPU count is not higher than 0."

    [ "$cpu_pool_count" -le "$nr_cpus" ] || \
        fail "Provided CPU count is higher than available CPUs - $nr_cpus."

    [ $((cpu_pool_count % nr_threads_per_core)) -eq 0 ] || \
        fail "The CPU count is not multiple of $nr_threads_per_core (threads per core)."

    # Iterate through each NUMA node and try to get a CPU pool that matches all requirements.
    for (( numa_node=0; numa_node<"$nr_numa_nodes"; numa_node++ ))
    do
        cpu_pool_array=()

        nr_cpus_per_numa_node="$(lscpu -p=node | grep -v "#" | grep -c "^$numa_node$")"

        if [ -z "$nr_cpus_per_numa_node" ] ; then
            continue
        fi

        # Skip CPU 0 and its siblings.
        if [ "$numa_node" -eq "$cpu_0_numa_node" ] ; then
            nr_cpus_per_numa_node=$((nr_cpus_per_numa_node - nr_threads_per_core))
        fi

        if [ "$cpu_pool_count" -gt "$nr_cpus_per_numa_node" ] ; then
            continue
        fi

        cpus_per_numa_node="$(lscpu -p=cpu,node | grep -v "#" | grep ",$numa_node$" | cut -d "," -f 1)"

        [ -z "$cpus_per_numa_node" ] && \
            fail "Failed to get the available CPUs of NUMA node $numa_node."

        # Iterate through each CPU from the current NUMA node and find full CPU cores
        # to add to the CPU pool.
        while read -r cpu_per_numa_node
        do
            # Skip CPU 0.
            if [ "$cpu_per_numa_node" -eq 0 ] ; then
                continue
            fi

            # Get all the CPU threads (siblings) from a CPU core.
            core_id="$(lscpu -p=cpu,core | grep -v "#" | grep "^$cpu_per_numa_node," | cut -d "," -f 2)"

            [ -z "$core_id" ] && fail "Failed to get the core id for CPU $cpu_per_numa_node."

            threads_per_core="$(lscpu -p=cpu,core | grep -v "#" | grep -v "^0," | grep ",$core_id$" | cut -d "," -f 1)"

            [ -z "$threads_per_core" ] && fail "Failed to get the threads for CPU core $core_id."

            threads_per_core_count="$(lscpu -p=cpu,core | grep -v "#" | grep -v "^0," | grep -c ",$core_id$")"

            # Check if full CPU core.
            if [ "$threads_per_core_count" -ne "$nr_threads_per_core" ] ; then
                continue
            fi

            # Include the CPU core in the CPU pool.
            while read -r cpu_thread
            do
                if [ "${#cpu_pool_array[@]}" -eq 0 ] ; then
                    cpu_pool_array=("$cpu_thread")
                    continue
                fi

                for cpu in "${cpu_pool_array[@]}"
                do
                    if [ "$cpu_thread" -eq "$cpu" ] ; then
                        continue 2
                    fi
                done

                cpu_pool_array=("${cpu_pool_array[@]}" "$cpu_thread")
            done < <(echo "$threads_per_core")

            # TODO: Setup also memory to check if enough in the NUMA node of the
            # auto-generated CPU pool. Otherwise, check the next availble NUMA node.
            # Found a CPU pool that matches all the necessary conditions, early exit.
            if [ "${#cpu_pool_array[@]}" -eq "$cpu_pool_count" ] ; then
                break 2
            fi
        done < <(echo "$cpus_per_numa_node")
    done

    # Not enough CPUs found to be added in the NE CPU pool.
    [ "${#cpu_pool_array[@]}" -ne "$cpu_pool_count" ] && \
        fail "Failed to find available CPUs for the NE CPU pool, iterated through all NUMA nodes."

    for cpu in "${cpu_pool_array[@]}"
    do
        if [ -z "$cpu_pool" ] ; then
            cpu_pool="$cpu"
            continue
        fi

        cpu_pool="$cpu_pool,$cpu"
    done

    if [ "$VERBOSE" = "1" ]; then
        echo "Auto-generated the enclave CPU pool - $cpu_pool."
    fi

    configure_cpu_pool "$cpu_pool"
}

# Script entry point.
[ "$#" -gt 0 ] || fail "No arguments given."

while getopts ":hd:cbrim:p:t:v" opt; do
    case ${opt} in
        h)  # Help was requested.
            print_usage
            exit 0
            ;;

        v)  # Set the verbosity flag. Use this
            # option first in order to print any
            # messages.
            VERBOSE="1"
            ;;

        d)  # Set the driver directory.
            DRIVER_DIR="$OPTARG"
            ;;

        i)  # Insert the driver.
            run_in_driver_dir driver_insert
            ;;

        r)  # Remove the driver.
            driver_remove
            ;;

        b)  # Build the driver.
            run_in_driver_dir driver_build
            ;;

        c)  # Clean the driver up.
            run_in_driver_dir driver_clean
            ;;

        m)  # Configure the huge page memory.
            configure_huge_pages "$OPTARG"
            ;;

        p)  # Configure the CPU pool.
            configure_cpu_pool "$OPTARG"
            ;;
        # TODO: Update to a more appropriate option letter. getopts does not
        # support long name options.
        # TODO: Have either -p or -t provided as a script option at a time,
        # make them mutually exclusive.
        t)  # Configure the CPU pool given the CPU count.
            configure_cpu_pool_by_cpu_count "$OPTARG"
            ;;
        s) # Skip shell reset at exit.
	    SKIP_SHELL_RESET=1
	    ;;

        \?) # Invalid option(s) provided.
            fail "Invalid argument(s) provided."
            ;;
    esac
done

# Reset the shell after configuring the driver.
if [ "$SHELL_RESET" -eq 1 ] && [ "$SKIP_SHELL_RESET" -eq 0 ]; then
    if [ "$VERBOSE" = "1" ]; then
        echo "Shell will be reset."
    fi
    sudo_run "exec su -l $THIS_USER"
fi

exit 0
